{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/delaygues/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/delaygues/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/delaygues/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/delaygues/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scripts.preprocessing import pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***this cells does not need to be run again as the results are saved in the csv file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cells does not need to be run again as the results are saved in the csv file\n",
    "data = pd.read_csv('data/tripadvisor_hotel_reviews.csv')\n",
    "data[\"cleaned_text\"] = pipeline.transform(data[\"Review\"].values)\n",
    "data.to_csv(\"data/cleaned_tripadvisor_reviews.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***creation of a simple class to run our model again and again in an easy way***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier:\n",
    "    \n",
    "    def __init__(self, model=None, vectorizer=None, class_weight=None):\n",
    "        self.model = model \n",
    "        self.vectorizer = vectorizer \n",
    "        self.X_train_tf = None\n",
    "        self.X_test_tf = None\n",
    "        \n",
    "    def train(self, X_train, y_train):\n",
    "        # Vectoriser les données d'entraînement\n",
    "        self.X_train_tf = self.vectorizer.fit_transform(X_train)\n",
    "        # Entraîner le modèle\n",
    "        self.model.fit(self.X_train_tf, y_train)\n",
    "        \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        # Transformer les données de test en utilisant le vectoriseur\n",
    "        self.X_test_tf = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        # Prédire et évaluer\n",
    "        y_pred = self.model.predict(self.X_test_tf)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        print(report)\n",
    "        \n",
    "        return acc, report\n",
    "    \n",
    "    def predict(self, text):\n",
    "        text_tf = self.vectorizer.transform([text])\n",
    "        return self.model.predict(text_tf)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6299097340814833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.62      0.68       292\n",
      "           2       0.45      0.38      0.41       333\n",
      "           3       0.44      0.25      0.32       432\n",
      "           4       0.55      0.50      0.53      1252\n",
      "           5       0.70      0.86      0.77      1790\n",
      "\n",
      "    accuracy                           0.63      4099\n",
      "   macro avg       0.58      0.52      0.54      4099\n",
      "weighted avg       0.61      0.63      0.61      4099\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6299097340814833,\n",
       " '              precision    recall  f1-score   support\\n\\n           1       0.75      0.62      0.68       292\\n           2       0.45      0.38      0.41       333\\n           3       0.44      0.25      0.32       432\\n           4       0.55      0.50      0.53      1252\\n           5       0.70      0.86      0.77      1790\\n\\n    accuracy                           0.63      4099\\n   macro avg       0.58      0.52      0.54      4099\\nweighted avg       0.61      0.63      0.61      4099\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('cleaned_tripadvisor_reviews.csv', index_col=0)\n",
    "\n",
    "X = dataset['cleaned_text']\n",
    "y = dataset['Rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "classifier = TextClassifier(model=LogisticRegression(max_iter=1000), vectorizer=TfidfVectorizer(max_features=5000, stop_words='english'))\n",
    "classifier.train(X_train, y_train)\n",
    "classifier.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we have an accuracy of 63% so it means that 63% of the predictions we made were correct. It is not a really good score but maybe the complexity of the datas and the amount of datas we have are not enough to have a better score. we cannot really judge the model only on this actually.\n",
    "\n",
    "An important thing to notice is the fact that the recall on the class 2 and 3 are really low. it means that the model is not able to differenciate 5 class. It is mainly classifying the datas in the most represented class as for exemple the class 5 has a high recall score what means that most of the 5 are classified as 5 but the precision is 70% so it meas that the model classified a lot as 5 but has a lot of false positive as well. It's a big sign of underfitting: the model can't classify the datas in class 2 or 3 so it just put them in the class that has the highest probability to be the right one.\n",
    "\n",
    "the low recall of the class 2 and 3 confirm our thought as it show that only 25% of the class 3 are classified as class 3 (more over the precision is 0.44 so the model is not only forgetting the class 3 but also classify badly the small amount of datas that it classify there)\n",
    "\n",
    "What we want to do is to try to improve the recall of the class 2 and 3. We will focus on this on the next notebook even if improving the accuracy to would be recommended\n",
    "\n",
    "NB: despite the fact that class 1 contains a small amount of datas the model manage them quite well. this class has probably really specific caracteristics that make it easy to classify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
